{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Analyzer Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this program we are creating a model, training the model and saving the strusture and data set weights to use for the video analyzer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/200\n",
      "28709/28709 [==============================] - 20s 700us/step - loss: 1.7121 - accuracy: 0.2996 - val_loss: 1.5684 - val_accuracy: 0.3642\n",
      "Epoch 2/200\n",
      "28709/28709 [==============================] - 20s 700us/step - loss: 1.4965 - accuracy: 0.4157 - val_loss: 1.3708 - val_accuracy: 0.4698\n",
      "Epoch 3/200\n",
      "28709/28709 [==============================] - 25s 863us/step - loss: 1.3958 - accuracy: 0.4556 - val_loss: 1.3394 - val_accuracy: 0.4851\n",
      "Epoch 4/200\n",
      "28709/28709 [==============================] - 26s 912us/step - loss: 1.3352 - accuracy: 0.4890 - val_loss: 1.2866 - val_accuracy: 0.5043\n",
      "Epoch 5/200\n",
      "28709/28709 [==============================] - 24s 825us/step - loss: 1.2907 - accuracy: 0.5009 - val_loss: 1.2425 - val_accuracy: 0.5222\n",
      "Epoch 6/200\n",
      "28709/28709 [==============================] - 34s 1ms/step - loss: 1.2498 - accuracy: 0.5176 - val_loss: 1.2415 - val_accuracy: 0.5280\n",
      "Epoch 7/200\n",
      "28709/28709 [==============================] - 32s 1ms/step - loss: 1.2245 - accuracy: 0.5277 - val_loss: 1.2107 - val_accuracy: 0.5336\n",
      "Epoch 8/200\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 1.1958 - accuracy: 0.5417 - val_loss: 1.1882 - val_accuracy: 0.5506\n",
      "Epoch 9/200\n",
      "28709/28709 [==============================] - 28s 985us/step - loss: 1.1719 - accuracy: 0.5521 - val_loss: 1.1748 - val_accuracy: 0.5575\n",
      "Epoch 10/200\n",
      "28709/28709 [==============================] - 28s 986us/step - loss: 1.1518 - accuracy: 0.5566 - val_loss: 1.1823 - val_accuracy: 0.5539\n",
      "Epoch 11/200\n",
      "28709/28709 [==============================] - 23s 817us/step - loss: 1.1371 - accuracy: 0.5621 - val_loss: 1.1846 - val_accuracy: 0.5444\n",
      "Epoch 12/200\n",
      "28709/28709 [==============================] - 22s 770us/step - loss: 1.1196 - accuracy: 0.5729 - val_loss: 1.1721 - val_accuracy: 0.5573\n",
      "Epoch 13/200\n",
      "28709/28709 [==============================] - 22s 754us/step - loss: 1.0998 - accuracy: 0.5786 - val_loss: 1.1590 - val_accuracy: 0.5595\n",
      "Epoch 14/200\n",
      "28709/28709 [==============================] - 22s 760us/step - loss: 1.0782 - accuracy: 0.5886 - val_loss: 1.1743 - val_accuracy: 0.5561\n",
      "Epoch 15/200\n",
      "28709/28709 [==============================] - 21s 747us/step - loss: 1.0535 - accuracy: 0.5961 - val_loss: 1.1609 - val_accuracy: 0.5587\n",
      "Epoch 16/200\n",
      "28709/28709 [==============================] - 22s 752us/step - loss: 1.0508 - accuracy: 0.5999 - val_loss: 1.1583 - val_accuracy: 0.5698\n",
      "Epoch 17/200\n",
      "28709/28709 [==============================] - 21s 746us/step - loss: 1.0210 - accuracy: 0.6093 - val_loss: 1.1737 - val_accuracy: 0.5600\n",
      "Epoch 18/200\n",
      "28709/28709 [==============================] - 22s 750us/step - loss: 1.0143 - accuracy: 0.6129 - val_loss: 1.1456 - val_accuracy: 0.5695\n",
      "Epoch 19/200\n",
      "28709/28709 [==============================] - 21s 748us/step - loss: 0.9963 - accuracy: 0.6186 - val_loss: 1.1638 - val_accuracy: 0.5684\n",
      "Epoch 20/200\n",
      "28709/28709 [==============================] - 21s 745us/step - loss: 0.9820 - accuracy: 0.6261 - val_loss: 1.1500 - val_accuracy: 0.5773\n",
      "Epoch 21/200\n",
      "28709/28709 [==============================] - 22s 757us/step - loss: 0.9680 - accuracy: 0.6326 - val_loss: 1.1980 - val_accuracy: 0.5715\n",
      "Epoch 22/200\n",
      "28709/28709 [==============================] - 22s 753us/step - loss: 0.9374 - accuracy: 0.6414 - val_loss: 1.1654 - val_accuracy: 0.5759\n",
      "Epoch 23/200\n",
      "28709/28709 [==============================] - 22s 754us/step - loss: 0.9362 - accuracy: 0.6418 - val_loss: 1.1776 - val_accuracy: 0.5645\n",
      "Epoch 24/200\n",
      "28709/28709 [==============================] - 22s 753us/step - loss: 0.9180 - accuracy: 0.6476 - val_loss: 1.1727 - val_accuracy: 0.5743\n",
      "Epoch 25/200\n",
      "28709/28709 [==============================] - 22s 772us/step - loss: 0.9012 - accuracy: 0.6566 - val_loss: 1.1820 - val_accuracy: 0.5698\n",
      "Epoch 26/200\n",
      "28709/28709 [==============================] - 21s 748us/step - loss: 0.8903 - accuracy: 0.6628 - val_loss: 1.1997 - val_accuracy: 0.5740\n",
      "Epoch 27/200\n",
      "28709/28709 [==============================] - 23s 787us/step - loss: 0.8718 - accuracy: 0.6684 - val_loss: 1.1869 - val_accuracy: 0.5637\n",
      "Epoch 28/200\n",
      "28709/28709 [==============================] - 21s 740us/step - loss: 0.8623 - accuracy: 0.6699 - val_loss: 1.2089 - val_accuracy: 0.5754\n",
      "Epoch 29/200\n",
      "28709/28709 [==============================] - 22s 755us/step - loss: 0.8459 - accuracy: 0.6790 - val_loss: 1.2078 - val_accuracy: 0.5740\n",
      "Epoch 30/200\n",
      "28709/28709 [==============================] - 22s 756us/step - loss: 0.8395 - accuracy: 0.6816 - val_loss: 1.2153 - val_accuracy: 0.5692\n",
      "Epoch 31/200\n",
      "28709/28709 [==============================] - 22s 753us/step - loss: 0.8233 - accuracy: 0.6883 - val_loss: 1.2130 - val_accuracy: 0.5765\n",
      "Epoch 32/200\n",
      "28709/28709 [==============================] - 22s 754us/step - loss: 0.8042 - accuracy: 0.6974 - val_loss: 1.2296 - val_accuracy: 0.5709\n",
      "Epoch 33/200\n",
      "28709/28709 [==============================] - 22s 781us/step - loss: 0.8067 - accuracy: 0.6953 - val_loss: 1.2155 - val_accuracy: 0.5737\n",
      "Epoch 34/200\n",
      "28709/28709 [==============================] - 21s 742us/step - loss: 0.7906 - accuracy: 0.7045 - val_loss: 1.2253 - val_accuracy: 0.5754\n",
      "Epoch 35/200\n",
      "28709/28709 [==============================] - 22s 759us/step - loss: 0.7748 - accuracy: 0.7084 - val_loss: 1.2481 - val_accuracy: 0.5731\n",
      "Epoch 36/200\n",
      "28709/28709 [==============================] - 22s 761us/step - loss: 0.7593 - accuracy: 0.7112 - val_loss: 1.2694 - val_accuracy: 0.5795\n",
      "Epoch 37/200\n",
      "28709/28709 [==============================] - 21s 748us/step - loss: 0.7498 - accuracy: 0.7168 - val_loss: 1.2715 - val_accuracy: 0.5701\n",
      "Epoch 38/200\n",
      "28709/28709 [==============================] - 22s 754us/step - loss: 0.7422 - accuracy: 0.7186 - val_loss: 1.2992 - val_accuracy: 0.5720\n",
      "Epoch 39/200\n",
      "28709/28709 [==============================] - 22s 756us/step - loss: 0.7292 - accuracy: 0.7252 - val_loss: 1.3065 - val_accuracy: 0.5737\n",
      "Epoch 40/200\n",
      "28709/28709 [==============================] - 22s 778us/step - loss: 0.7202 - accuracy: 0.7304 - val_loss: 1.2951 - val_accuracy: 0.5751\n",
      "Epoch 41/200\n",
      "28709/28709 [==============================] - 21s 749us/step - loss: 0.7059 - accuracy: 0.7369 - val_loss: 1.3409 - val_accuracy: 0.5717\n",
      "Epoch 42/200\n",
      "28709/28709 [==============================] - 21s 748us/step - loss: 0.7066 - accuracy: 0.7366 - val_loss: 1.3128 - val_accuracy: 0.5737\n",
      "Epoch 43/200\n",
      "28709/28709 [==============================] - 22s 762us/step - loss: 0.6945 - accuracy: 0.7423 - val_loss: 1.3140 - val_accuracy: 0.5751\n",
      "Epoch 44/200\n",
      "28709/28709 [==============================] - 22s 750us/step - loss: 0.6932 - accuracy: 0.7398 - val_loss: 1.3299 - val_accuracy: 0.5726\n",
      "Epoch 45/200\n",
      "28709/28709 [==============================] - 22s 751us/step - loss: 0.6719 - accuracy: 0.7471 - val_loss: 1.3440 - val_accuracy: 0.5731\n",
      "Epoch 46/200\n",
      "28709/28709 [==============================] - 22s 758us/step - loss: 0.6682 - accuracy: 0.7520 - val_loss: 1.3592 - val_accuracy: 0.5773\n",
      "Epoch 47/200\n",
      "28709/28709 [==============================] - 21s 746us/step - loss: 0.6589 - accuracy: 0.7550 - val_loss: 1.3813 - val_accuracy: 0.5743\n",
      "Epoch 48/200\n",
      "28709/28709 [==============================] - 22s 755us/step - loss: 0.6517 - accuracy: 0.7599 - val_loss: 1.3929 - val_accuracy: 0.5745\n",
      "Epoch 49/200\n",
      "28709/28709 [==============================] - 23s 784us/step - loss: 0.6358 - accuracy: 0.7654 - val_loss: 1.3796 - val_accuracy: 0.5731\n",
      "Epoch 50/200\n",
      "28709/28709 [==============================] - 24s 820us/step - loss: 0.6429 - accuracy: 0.7633 - val_loss: 1.3744 - val_accuracy: 0.5834\n",
      "Epoch 51/200\n",
      "28709/28709 [==============================] - 24s 822us/step - loss: 0.6273 - accuracy: 0.7675 - val_loss: 1.3598 - val_accuracy: 0.5712\n",
      "Epoch 52/200\n",
      "28709/28709 [==============================] - 24s 837us/step - loss: 0.6167 - accuracy: 0.7720 - val_loss: 1.4035 - val_accuracy: 0.5648\n",
      "Epoch 53/200\n",
      "28709/28709 [==============================] - 25s 869us/step - loss: 0.6114 - accuracy: 0.7736 - val_loss: 1.4233 - val_accuracy: 0.5706\n",
      "Epoch 54/200\n",
      "28709/28709 [==============================] - 23s 818us/step - loss: 0.5970 - accuracy: 0.7792 - val_loss: 1.3806 - val_accuracy: 0.5776\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 25s 862us/step - loss: 0.6074 - accuracy: 0.7770 - val_loss: 1.3874 - val_accuracy: 0.5729\n",
      "Epoch 56/200\n",
      "28709/28709 [==============================] - 23s 791us/step - loss: 0.5829 - accuracy: 0.7821 - val_loss: 1.4117 - val_accuracy: 0.5795\n",
      "Epoch 57/200\n",
      "28709/28709 [==============================] - 22s 751us/step - loss: 0.5803 - accuracy: 0.7858 - val_loss: 1.3909 - val_accuracy: 0.5684\n",
      "Epoch 58/200\n",
      "28709/28709 [==============================] - 21s 749us/step - loss: 0.5729 - accuracy: 0.7892 - val_loss: 1.4525 - val_accuracy: 0.5662\n",
      "Epoch 59/200\n",
      "28709/28709 [==============================] - 22s 756us/step - loss: 0.5802 - accuracy: 0.7859 - val_loss: 1.4297 - val_accuracy: 0.5723\n",
      "Epoch 60/200\n",
      "28709/28709 [==============================] - 22s 767us/step - loss: 0.5710 - accuracy: 0.7919 - val_loss: 1.4346 - val_accuracy: 0.5801\n",
      "Epoch 61/200\n",
      "28709/28709 [==============================] - 22s 767us/step - loss: 0.5567 - accuracy: 0.7943 - val_loss: 1.4363 - val_accuracy: 0.5745\n",
      "Epoch 62/200\n",
      "28709/28709 [==============================] - 22s 772us/step - loss: 0.5572 - accuracy: 0.7964 - val_loss: 1.4334 - val_accuracy: 0.5801\n",
      "Epoch 63/200\n",
      "28709/28709 [==============================] - 23s 791us/step - loss: 0.5483 - accuracy: 0.8001 - val_loss: 1.4117 - val_accuracy: 0.5768\n",
      "Epoch 64/200\n",
      "28709/28709 [==============================] - 22s 778us/step - loss: 0.5404 - accuracy: 0.8006 - val_loss: 1.4524 - val_accuracy: 0.5773\n",
      "Epoch 65/200\n",
      "28709/28709 [==============================] - 23s 797us/step - loss: 0.5325 - accuracy: 0.8070 - val_loss: 1.4380 - val_accuracy: 0.5698\n",
      "Epoch 66/200\n",
      "28709/28709 [==============================] - 21s 746us/step - loss: 0.5355 - accuracy: 0.8055 - val_loss: 1.5076 - val_accuracy: 0.5770\n",
      "Epoch 67/200\n",
      "28709/28709 [==============================] - 21s 748us/step - loss: 0.5270 - accuracy: 0.8076 - val_loss: 1.4952 - val_accuracy: 0.5795\n",
      "Epoch 68/200\n",
      "28709/28709 [==============================] - 22s 752us/step - loss: 0.5209 - accuracy: 0.8105 - val_loss: 1.5120 - val_accuracy: 0.5759\n",
      "Epoch 69/200\n",
      "28709/28709 [==============================] - 21s 748us/step - loss: 0.5182 - accuracy: 0.8146 - val_loss: 1.4944 - val_accuracy: 0.5751\n",
      "Epoch 70/200\n",
      "28709/28709 [==============================] - 21s 746us/step - loss: 0.5228 - accuracy: 0.8113 - val_loss: 1.4619 - val_accuracy: 0.5687\n",
      "Epoch 71/200\n",
      "28709/28709 [==============================] - 21s 746us/step - loss: 0.5051 - accuracy: 0.8189 - val_loss: 1.5685 - val_accuracy: 0.5848\n",
      "Epoch 72/200\n",
      "28709/28709 [==============================] - 21s 745us/step - loss: 0.5015 - accuracy: 0.8177 - val_loss: 1.5467 - val_accuracy: 0.5787\n",
      "Epoch 73/200\n",
      "28709/28709 [==============================] - 21s 746us/step - loss: 0.5027 - accuracy: 0.8175 - val_loss: 1.4651 - val_accuracy: 0.5743\n",
      "Epoch 74/200\n",
      "28709/28709 [==============================] - 23s 784us/step - loss: 0.4950 - accuracy: 0.8219 - val_loss: 1.4988 - val_accuracy: 0.5776\n",
      "Epoch 75/200\n",
      "28709/28709 [==============================] - 21s 747us/step - loss: 0.5007 - accuracy: 0.8183 - val_loss: 1.5403 - val_accuracy: 0.5698\n",
      "Epoch 76/200\n",
      "28709/28709 [==============================] - 22s 753us/step - loss: 0.4980 - accuracy: 0.8196 - val_loss: 1.4659 - val_accuracy: 0.5773\n",
      "Epoch 77/200\n",
      "28709/28709 [==============================] - 22s 751us/step - loss: 0.4903 - accuracy: 0.8250 - val_loss: 1.5031 - val_accuracy: 0.5773\n",
      "Epoch 78/200\n",
      "28709/28709 [==============================] - 22s 752us/step - loss: 0.4843 - accuracy: 0.8272 - val_loss: 1.5523 - val_accuracy: 0.5904\n",
      "Epoch 79/200\n",
      "28709/28709 [==============================] - 22s 754us/step - loss: 0.4702 - accuracy: 0.8307 - val_loss: 1.5393 - val_accuracy: 0.5776\n",
      "Epoch 80/200\n",
      "28709/28709 [==============================] - 21s 745us/step - loss: 0.4687 - accuracy: 0.8311 - val_loss: 1.5429 - val_accuracy: 0.5751\n",
      "Epoch 81/200\n",
      "28709/28709 [==============================] - 22s 756us/step - loss: 0.4845 - accuracy: 0.8282 - val_loss: 1.5770 - val_accuracy: 0.5690\n",
      "Epoch 82/200\n",
      "28709/28709 [==============================] - 22s 753us/step - loss: 0.4613 - accuracy: 0.8340 - val_loss: 1.5819 - val_accuracy: 0.5737\n",
      "Epoch 83/200\n",
      "28709/28709 [==============================] - 22s 764us/step - loss: 0.4568 - accuracy: 0.8364 - val_loss: 1.5460 - val_accuracy: 0.5743\n",
      "Epoch 84/200\n",
      "28709/28709 [==============================] - 22s 781us/step - loss: 0.4562 - accuracy: 0.8373 - val_loss: 1.6379 - val_accuracy: 0.5673\n",
      "Epoch 85/200\n",
      "28709/28709 [==============================] - 21s 749us/step - loss: 0.4665 - accuracy: 0.8332 - val_loss: 1.5504 - val_accuracy: 0.5665\n",
      "Epoch 86/200\n",
      "28709/28709 [==============================] - 21s 748us/step - loss: 0.4575 - accuracy: 0.8360 - val_loss: 1.6537 - val_accuracy: 0.5740\n",
      "Epoch 87/200\n",
      "28709/28709 [==============================] - 22s 760us/step - loss: 0.4570 - accuracy: 0.8384 - val_loss: 1.5878 - val_accuracy: 0.5731\n",
      "Epoch 88/200\n",
      "28709/28709 [==============================] - 22s 750us/step - loss: 0.4468 - accuracy: 0.8414 - val_loss: 1.5802 - val_accuracy: 0.5698\n",
      "Epoch 89/200\n",
      "28709/28709 [==============================] - 22s 752us/step - loss: 0.4499 - accuracy: 0.8390 - val_loss: 1.5006 - val_accuracy: 0.5695\n",
      "Epoch 90/200\n",
      "28709/28709 [==============================] - 22s 764us/step - loss: 0.4288 - accuracy: 0.8476 - val_loss: 1.6096 - val_accuracy: 0.5734\n",
      "Epoch 91/200\n",
      "28709/28709 [==============================] - 21s 722us/step - loss: 0.4426 - accuracy: 0.8432 - val_loss: 1.6082 - val_accuracy: 0.5793\n",
      "Epoch 92/200\n",
      "28709/28709 [==============================] - 21s 739us/step - loss: 0.4398 - accuracy: 0.8412 - val_loss: 1.5716 - val_accuracy: 0.5770\n",
      "Epoch 93/200\n",
      "28709/28709 [==============================] - 22s 750us/step - loss: 0.4298 - accuracy: 0.8467 - val_loss: 1.6321 - val_accuracy: 0.5681\n",
      "Epoch 94/200\n",
      "28709/28709 [==============================] - 21s 737us/step - loss: 0.4421 - accuracy: 0.8437 - val_loss: 1.6645 - val_accuracy: 0.5670\n",
      "Epoch 95/200\n",
      "28709/28709 [==============================] - 21s 733us/step - loss: 0.4287 - accuracy: 0.8474 - val_loss: 1.6498 - val_accuracy: 0.5768\n",
      "Epoch 96/200\n",
      "28709/28709 [==============================] - 21s 740us/step - loss: 0.4178 - accuracy: 0.8523 - val_loss: 1.6716 - val_accuracy: 0.5809\n",
      "Epoch 97/200\n",
      "28709/28709 [==============================] - 21s 732us/step - loss: 0.4209 - accuracy: 0.8512 - val_loss: 1.5697 - val_accuracy: 0.5770\n",
      "Epoch 98/200\n",
      "28709/28709 [==============================] - 21s 749us/step - loss: 0.4232 - accuracy: 0.8513 - val_loss: 1.6036 - val_accuracy: 0.5659\n",
      "Epoch 99/200\n",
      "28709/28709 [==============================] - 21s 720us/step - loss: 0.4103 - accuracy: 0.8559 - val_loss: 1.6714 - val_accuracy: 0.5737\n",
      "Epoch 100/200\n",
      "28709/28709 [==============================] - 21s 727us/step - loss: 0.4215 - accuracy: 0.8516 - val_loss: 1.6861 - val_accuracy: 0.5648\n",
      "Epoch 101/200\n",
      "28709/28709 [==============================] - 21s 731us/step - loss: 0.4246 - accuracy: 0.8512 - val_loss: 1.6276 - val_accuracy: 0.5645\n",
      "Epoch 102/200\n",
      "28709/28709 [==============================] - 23s 787us/step - loss: 0.4049 - accuracy: 0.8582 - val_loss: 1.6521 - val_accuracy: 0.5662\n",
      "Epoch 103/200\n",
      "28709/28709 [==============================] - 21s 727us/step - loss: 0.4004 - accuracy: 0.8609 - val_loss: 1.6687 - val_accuracy: 0.5770\n",
      "Epoch 104/200\n",
      "28709/28709 [==============================] - 21s 746us/step - loss: 0.4076 - accuracy: 0.8559 - val_loss: 1.6618 - val_accuracy: 0.5681\n",
      "Epoch 105/200\n",
      "28709/28709 [==============================] - 21s 728us/step - loss: 0.4132 - accuracy: 0.8545 - val_loss: 1.7388 - val_accuracy: 0.5729\n",
      "Epoch 106/200\n",
      "28709/28709 [==============================] - 21s 724us/step - loss: 0.4023 - accuracy: 0.8571 - val_loss: 1.7125 - val_accuracy: 0.5720\n",
      "Epoch 107/200\n",
      "28709/28709 [==============================] - 21s 726us/step - loss: 0.3945 - accuracy: 0.8603 - val_loss: 1.6987 - val_accuracy: 0.5667\n",
      "Epoch 108/200\n",
      "28709/28709 [==============================] - 22s 776us/step - loss: 0.4029 - accuracy: 0.8595 - val_loss: 1.7418 - val_accuracy: 0.5612\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 21s 717us/step - loss: 0.3934 - accuracy: 0.8624 - val_loss: 1.6936 - val_accuracy: 0.5720\n",
      "Epoch 110/200\n",
      "28709/28709 [==============================] - 21s 725us/step - loss: 0.3969 - accuracy: 0.8595 - val_loss: 1.7946 - val_accuracy: 0.5815\n",
      "Epoch 111/200\n",
      "28709/28709 [==============================] - 21s 744us/step - loss: 0.3963 - accuracy: 0.8614 - val_loss: 1.7033 - val_accuracy: 0.5704\n",
      "Epoch 112/200\n",
      "28709/28709 [==============================] - 21s 732us/step - loss: 0.3958 - accuracy: 0.8606 - val_loss: 1.7423 - val_accuracy: 0.5678\n",
      "Epoch 113/200\n",
      "28709/28709 [==============================] - 21s 734us/step - loss: 0.3858 - accuracy: 0.8631 - val_loss: 1.7625 - val_accuracy: 0.5706\n",
      "Epoch 114/200\n",
      "28709/28709 [==============================] - 21s 731us/step - loss: 0.3813 - accuracy: 0.8655 - val_loss: 1.6999 - val_accuracy: 0.5784\n",
      "Epoch 115/200\n",
      "28709/28709 [==============================] - 21s 730us/step - loss: 0.3839 - accuracy: 0.8652 - val_loss: 1.7267 - val_accuracy: 0.5731\n",
      "Epoch 116/200\n",
      "28709/28709 [==============================] - 21s 727us/step - loss: 0.3735 - accuracy: 0.8698 - val_loss: 1.8204 - val_accuracy: 0.5676\n",
      "Epoch 117/200\n",
      "28709/28709 [==============================] - 21s 720us/step - loss: 0.3874 - accuracy: 0.8660 - val_loss: 1.7520 - val_accuracy: 0.5678\n",
      "Epoch 118/200\n",
      "28709/28709 [==============================] - 21s 737us/step - loss: 0.3845 - accuracy: 0.8684 - val_loss: 1.6754 - val_accuracy: 0.5715\n",
      "Epoch 119/200\n",
      "28709/28709 [==============================] - 24s 827us/step - loss: 0.3686 - accuracy: 0.8717 - val_loss: 1.7735 - val_accuracy: 0.5690\n",
      "Epoch 120/200\n",
      "28709/28709 [==============================] - 22s 764us/step - loss: 0.3647 - accuracy: 0.8729 - val_loss: 1.7882 - val_accuracy: 0.5695\n",
      "Epoch 121/200\n",
      "28709/28709 [==============================] - 22s 763us/step - loss: 0.3776 - accuracy: 0.8692 - val_loss: 1.6904 - val_accuracy: 0.5678\n",
      "Epoch 122/200\n",
      "28709/28709 [==============================] - 22s 750us/step - loss: 0.3810 - accuracy: 0.8691 - val_loss: 1.6546 - val_accuracy: 0.5723\n",
      "Epoch 123/200\n",
      "28709/28709 [==============================] - 21s 736us/step - loss: 0.3670 - accuracy: 0.8727 - val_loss: 1.7523 - val_accuracy: 0.5734\n",
      "Epoch 124/200\n",
      "28709/28709 [==============================] - 21s 735us/step - loss: 0.3662 - accuracy: 0.8714 - val_loss: 1.7386 - val_accuracy: 0.5676\n",
      "Epoch 125/200\n",
      "28709/28709 [==============================] - 21s 742us/step - loss: 0.3666 - accuracy: 0.8732 - val_loss: 1.7789 - val_accuracy: 0.5704\n",
      "Epoch 126/200\n",
      "28709/28709 [==============================] - 21s 724us/step - loss: 0.3725 - accuracy: 0.8707 - val_loss: 1.7670 - val_accuracy: 0.5715\n",
      "Epoch 127/200\n",
      "28709/28709 [==============================] - 21s 725us/step - loss: 0.3577 - accuracy: 0.8741 - val_loss: 1.8502 - val_accuracy: 0.5701\n",
      "Epoch 128/200\n",
      "28709/28709 [==============================] - 22s 757us/step - loss: 0.3653 - accuracy: 0.8743 - val_loss: 1.8424 - val_accuracy: 0.5648\n",
      "Epoch 129/200\n",
      "28709/28709 [==============================] - 21s 718us/step - loss: 0.3582 - accuracy: 0.8783 - val_loss: 1.7523 - val_accuracy: 0.5704\n",
      "Epoch 130/200\n",
      "28709/28709 [==============================] - 21s 722us/step - loss: 0.3596 - accuracy: 0.8753 - val_loss: 1.6978 - val_accuracy: 0.5765\n",
      "Epoch 131/200\n",
      "28709/28709 [==============================] - 21s 721us/step - loss: 0.3493 - accuracy: 0.8816 - val_loss: 1.7868 - val_accuracy: 0.5717\n",
      "Epoch 132/200\n",
      "28709/28709 [==============================] - 21s 721us/step - loss: 0.3626 - accuracy: 0.8767 - val_loss: 1.7415 - val_accuracy: 0.5695\n",
      "Epoch 133/200\n",
      "28709/28709 [==============================] - 21s 734us/step - loss: 0.3585 - accuracy: 0.8761 - val_loss: 1.7696 - val_accuracy: 0.5542\n",
      "Epoch 134/200\n",
      "28709/28709 [==============================] - 21s 732us/step - loss: 0.3586 - accuracy: 0.8784 - val_loss: 1.7078 - val_accuracy: 0.5787\n",
      "Epoch 135/200\n",
      "28709/28709 [==============================] - 22s 757us/step - loss: 0.3543 - accuracy: 0.8790 - val_loss: 1.7979 - val_accuracy: 0.5584\n",
      "Epoch 136/200\n",
      "28709/28709 [==============================] - 21s 731us/step - loss: 0.3393 - accuracy: 0.8826 - val_loss: 1.9030 - val_accuracy: 0.5614\n",
      "Epoch 137/200\n",
      "28709/28709 [==============================] - 21s 734us/step - loss: 0.3521 - accuracy: 0.8777 - val_loss: 1.7804 - val_accuracy: 0.5701\n",
      "Epoch 138/200\n",
      "28709/28709 [==============================] - 21s 729us/step - loss: 0.3534 - accuracy: 0.8808 - val_loss: 1.7827 - val_accuracy: 0.5637\n",
      "Epoch 139/200\n",
      "28709/28709 [==============================] - 21s 727us/step - loss: 0.3432 - accuracy: 0.8808 - val_loss: 1.7703 - val_accuracy: 0.5795\n",
      "Epoch 140/200\n",
      "28709/28709 [==============================] - 21s 748us/step - loss: 0.3444 - accuracy: 0.8804 - val_loss: 1.7532 - val_accuracy: 0.5762\n",
      "Epoch 141/200\n",
      "28709/28709 [==============================] - 21s 747us/step - loss: 0.3438 - accuracy: 0.8826 - val_loss: 1.8587 - val_accuracy: 0.5692\n",
      "Epoch 142/200\n",
      "28709/28709 [==============================] - 21s 727us/step - loss: 0.3372 - accuracy: 0.8848 - val_loss: 1.8349 - val_accuracy: 0.5670\n",
      "Epoch 143/200\n",
      "28709/28709 [==============================] - 21s 728us/step - loss: 0.3492 - accuracy: 0.8811 - val_loss: 1.8227 - val_accuracy: 0.5670\n",
      "Epoch 144/200\n",
      "28709/28709 [==============================] - 23s 801us/step - loss: 0.3446 - accuracy: 0.8827 - val_loss: 1.8737 - val_accuracy: 0.5603\n",
      "Epoch 145/200\n",
      "28709/28709 [==============================] - 21s 746us/step - loss: 0.3437 - accuracy: 0.8831 - val_loss: 1.8197 - val_accuracy: 0.5639\n",
      "Epoch 146/200\n",
      "28709/28709 [==============================] - 21s 738us/step - loss: 0.3371 - accuracy: 0.8850 - val_loss: 1.8553 - val_accuracy: 0.5667\n",
      "Epoch 147/200\n",
      "28709/28709 [==============================] - 21s 721us/step - loss: 0.3347 - accuracy: 0.8850 - val_loss: 1.7782 - val_accuracy: 0.5681\n",
      "Epoch 148/200\n",
      "28709/28709 [==============================] - 21s 718us/step - loss: 0.3517 - accuracy: 0.8805 - val_loss: 1.8704 - val_accuracy: 0.5626\n",
      "Epoch 149/200\n",
      "28709/28709 [==============================] - 21s 726us/step - loss: 0.3367 - accuracy: 0.8861 - val_loss: 1.8361 - val_accuracy: 0.5681\n",
      "Epoch 150/200\n",
      "28709/28709 [==============================] - 21s 727us/step - loss: 0.3471 - accuracy: 0.8813 - val_loss: 1.8083 - val_accuracy: 0.5695\n",
      "Epoch 151/200\n",
      "28709/28709 [==============================] - 21s 729us/step - loss: 0.3307 - accuracy: 0.8851 - val_loss: 1.8857 - val_accuracy: 0.5648\n",
      "Epoch 152/200\n",
      "28709/28709 [==============================] - 21s 721us/step - loss: 0.3440 - accuracy: 0.8816 - val_loss: 1.9132 - val_accuracy: 0.5620\n",
      "Epoch 153/200\n",
      "28709/28709 [==============================] - 22s 749us/step - loss: 0.3204 - accuracy: 0.8932 - val_loss: 1.8910 - val_accuracy: 0.5595\n",
      "Epoch 154/200\n",
      "28709/28709 [==============================] - 21s 727us/step - loss: 0.3326 - accuracy: 0.8877 - val_loss: 1.8639 - val_accuracy: 0.5684\n",
      "Epoch 155/200\n",
      "28709/28709 [==============================] - 21s 721us/step - loss: 0.3198 - accuracy: 0.8906 - val_loss: 1.8559 - val_accuracy: 0.5695\n",
      "Epoch 156/200\n",
      "28709/28709 [==============================] - 21s 724us/step - loss: 0.3282 - accuracy: 0.8888 - val_loss: 1.8815 - val_accuracy: 0.5681\n",
      "Epoch 157/200\n",
      "28709/28709 [==============================] - 21s 747us/step - loss: 0.3396 - accuracy: 0.8857 - val_loss: 1.8930 - val_accuracy: 0.5556\n",
      "Epoch 158/200\n",
      "28709/28709 [==============================] - 21s 717us/step - loss: 0.3308 - accuracy: 0.8890 - val_loss: 1.8315 - val_accuracy: 0.5765\n",
      "Epoch 159/200\n",
      "28709/28709 [==============================] - 21s 724us/step - loss: 0.3125 - accuracy: 0.8933 - val_loss: 1.9270 - val_accuracy: 0.5617\n",
      "Epoch 160/200\n",
      "28709/28709 [==============================] - 21s 734us/step - loss: 0.3332 - accuracy: 0.8889 - val_loss: 1.8980 - val_accuracy: 0.5573\n",
      "Epoch 161/200\n",
      "28709/28709 [==============================] - 21s 731us/step - loss: 0.3267 - accuracy: 0.8902 - val_loss: 1.7542 - val_accuracy: 0.5587\n",
      "Epoch 162/200\n",
      "28709/28709 [==============================] - 24s 836us/step - loss: 0.3220 - accuracy: 0.8905 - val_loss: 1.8008 - val_accuracy: 0.5606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200\n",
      "28709/28709 [==============================] - 21s 735us/step - loss: 0.3123 - accuracy: 0.8934 - val_loss: 1.9119 - val_accuracy: 0.5525\n",
      "Epoch 164/200\n",
      "28709/28709 [==============================] - 21s 748us/step - loss: 0.3143 - accuracy: 0.8945 - val_loss: 1.8915 - val_accuracy: 0.5578\n",
      "Epoch 165/200\n",
      "28709/28709 [==============================] - 21s 743us/step - loss: 0.3084 - accuracy: 0.8954 - val_loss: 2.0704 - val_accuracy: 0.5614\n",
      "Epoch 166/200\n",
      "28709/28709 [==============================] - 22s 754us/step - loss: 0.3269 - accuracy: 0.8920 - val_loss: 1.8376 - val_accuracy: 0.5659\n",
      "Epoch 167/200\n",
      "28709/28709 [==============================] - 21s 742us/step - loss: 0.3266 - accuracy: 0.8920 - val_loss: 1.8652 - val_accuracy: 0.5673\n",
      "Epoch 168/200\n",
      "28709/28709 [==============================] - 21s 721us/step - loss: 0.3165 - accuracy: 0.8934 - val_loss: 1.9137 - val_accuracy: 0.5506\n",
      "Epoch 169/200\n",
      "28709/28709 [==============================] - 21s 728us/step - loss: 0.3188 - accuracy: 0.8906 - val_loss: 1.9055 - val_accuracy: 0.5651\n",
      "Epoch 170/200\n",
      "28709/28709 [==============================] - 22s 751us/step - loss: 0.3106 - accuracy: 0.8949 - val_loss: 1.8482 - val_accuracy: 0.5648\n",
      "Epoch 171/200\n",
      "28709/28709 [==============================] - 21s 732us/step - loss: 0.3096 - accuracy: 0.8967 - val_loss: 1.9018 - val_accuracy: 0.5603\n",
      "Epoch 172/200\n",
      "28709/28709 [==============================] - 21s 733us/step - loss: 0.3020 - accuracy: 0.8992 - val_loss: 1.8891 - val_accuracy: 0.5759\n",
      "Epoch 173/200\n",
      "28709/28709 [==============================] - 21s 735us/step - loss: 0.3336 - accuracy: 0.8887 - val_loss: 1.8486 - val_accuracy: 0.5659\n",
      "Epoch 174/200\n",
      "28709/28709 [==============================] - 21s 719us/step - loss: 0.3151 - accuracy: 0.8937 - val_loss: 1.9542 - val_accuracy: 0.5587\n",
      "Epoch 175/200\n",
      "28709/28709 [==============================] - 21s 727us/step - loss: 0.3131 - accuracy: 0.8943 - val_loss: 1.8321 - val_accuracy: 0.5779\n",
      "Epoch 176/200\n",
      "28709/28709 [==============================] - 21s 721us/step - loss: 0.3125 - accuracy: 0.8962 - val_loss: 1.8919 - val_accuracy: 0.5709\n",
      "Epoch 177/200\n",
      "28709/28709 [==============================] - 24s 820us/step - loss: 0.3074 - accuracy: 0.8974 - val_loss: 1.7846 - val_accuracy: 0.5692\n",
      "Epoch 178/200\n",
      "28709/28709 [==============================] - 24s 853us/step - loss: 0.3189 - accuracy: 0.8925 - val_loss: 1.8278 - val_accuracy: 0.5614\n",
      "Epoch 179/200\n",
      "28709/28709 [==============================] - 21s 738us/step - loss: 0.3070 - accuracy: 0.8995 - val_loss: 1.8632 - val_accuracy: 0.5617\n",
      "Epoch 180/200\n",
      "28709/28709 [==============================] - 22s 774us/step - loss: 0.2933 - accuracy: 0.9015 - val_loss: 1.8634 - val_accuracy: 0.5614\n",
      "Epoch 181/200\n",
      "28709/28709 [==============================] - 21s 723us/step - loss: 0.3026 - accuracy: 0.9004 - val_loss: 1.8695 - val_accuracy: 0.5678\n",
      "Epoch 182/200\n",
      "28709/28709 [==============================] - 21s 733us/step - loss: 0.3081 - accuracy: 0.8982 - val_loss: 1.8489 - val_accuracy: 0.5637\n",
      "Epoch 183/200\n",
      "28709/28709 [==============================] - 21s 725us/step - loss: 0.3015 - accuracy: 0.9010 - val_loss: 1.8688 - val_accuracy: 0.5695\n",
      "Epoch 184/200\n",
      "28709/28709 [==============================] - 21s 719us/step - loss: 0.2987 - accuracy: 0.9011 - val_loss: 1.9546 - val_accuracy: 0.5723\n",
      "Epoch 185/200\n",
      "28709/28709 [==============================] - 21s 726us/step - loss: 0.3233 - accuracy: 0.8900 - val_loss: 1.9380 - val_accuracy: 0.5606\n",
      "Epoch 186/200\n",
      "28709/28709 [==============================] - 21s 737us/step - loss: 0.2924 - accuracy: 0.8999 - val_loss: 1.9882 - val_accuracy: 0.5656\n",
      "Epoch 187/200\n",
      "28709/28709 [==============================] - 21s 725us/step - loss: 0.3034 - accuracy: 0.9010 - val_loss: 1.8929 - val_accuracy: 0.5651\n",
      "Epoch 188/200\n",
      "28709/28709 [==============================] - 21s 721us/step - loss: 0.3039 - accuracy: 0.8997 - val_loss: 1.9279 - val_accuracy: 0.5717\n",
      "Epoch 189/200\n",
      "28709/28709 [==============================] - 22s 768us/step - loss: 0.2993 - accuracy: 0.9007 - val_loss: 2.0233 - val_accuracy: 0.5653\n",
      "Epoch 190/200\n",
      "28709/28709 [==============================] - 24s 844us/step - loss: 0.3055 - accuracy: 0.8979 - val_loss: 1.9090 - val_accuracy: 0.5651\n",
      "Epoch 191/200\n",
      "28709/28709 [==============================] - 21s 734us/step - loss: 0.2926 - accuracy: 0.9034 - val_loss: 1.9665 - val_accuracy: 0.5651\n",
      "Epoch 192/200\n",
      "28709/28709 [==============================] - 21s 748us/step - loss: 0.2869 - accuracy: 0.9040 - val_loss: 2.0257 - val_accuracy: 0.5676\n",
      "Epoch 193/200\n",
      "28709/28709 [==============================] - 21s 721us/step - loss: 0.2988 - accuracy: 0.9026 - val_loss: 1.9621 - val_accuracy: 0.5620\n",
      "Epoch 194/200\n",
      "28709/28709 [==============================] - 21s 721us/step - loss: 0.2956 - accuracy: 0.9015 - val_loss: 2.0446 - val_accuracy: 0.5651\n",
      "Epoch 195/200\n",
      "28709/28709 [==============================] - 21s 748us/step - loss: 0.3066 - accuracy: 0.8990 - val_loss: 1.9571 - val_accuracy: 0.5559\n",
      "Epoch 196/200\n",
      "28709/28709 [==============================] - 24s 820us/step - loss: 0.2954 - accuracy: 0.9003 - val_loss: 1.9952 - val_accuracy: 0.5717\n",
      "Epoch 197/200\n",
      "28709/28709 [==============================] - 25s 858us/step - loss: 0.2898 - accuracy: 0.9033 - val_loss: 1.9720 - val_accuracy: 0.5709\n",
      "Epoch 198/200\n",
      "28709/28709 [==============================] - 22s 758us/step - loss: 0.2897 - accuracy: 0.9027 - val_loss: 1.9888 - val_accuracy: 0.5637\n",
      "Epoch 199/200\n",
      "28709/28709 [==============================] - 22s 775us/step - loss: 0.2859 - accuracy: 0.9039 - val_loss: 1.9664 - val_accuracy: 0.5634\n",
      "Epoch 200/200\n",
      "28709/28709 [==============================] - 21s 746us/step - loss: 0.2964 - accuracy: 0.9013 - val_loss: 1.9055 - val_accuracy: 0.5659\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv('fer2013.csv')\n",
    "\n",
    "\n",
    "# Splitting the single pixel values of each picture and apending to array (creating a 2D array)\n",
    "pixels = []\n",
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    pixels.append(np.array(val, 'float32'))\n",
    "\n",
    "#Splitting the training and testing data (10% is testing data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(pixels, df['emotion'], test_size=0.1)\n",
    "\n",
    "x_train = np.array(x_train,'float32')\n",
    "x_test = np.array(x_test, 'float32')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 7)\n",
    "y_test = keras.utils.to_categorical(y_test, 7)\n",
    "\n",
    "#Normalizing the data values\n",
    "x_train = (x_train - np.mean(x_train, axis=0))/np.std(x_train, axis=0)\n",
    "x_test = (x_test - np.mean(x_test, axis=0))/np.std(x_test, axis=0)\n",
    "\n",
    "#Reshaping the size of the array\n",
    "x_train = x_train.reshape(x_train.shape[0], 48, 48, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 48, 48, 1)\n",
    "\n",
    "\n",
    "#1st convolution layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=(48, 48, 1), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(7, activation=\"softmax\"))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "#Training the model with 200 iterations, and allows data to shuffle order\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=200,\n",
    "    validation_data=(x_test, y_test),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "#Saving the model strusture and weights to files for use in video analyzing\n",
    "model_structure = model.to_json()\n",
    "f = Path(\"model_structure.json\")\n",
    "f.write_text(model_structure)\n",
    "\n",
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Note:\n",
    "\n",
    "After the program is trained, it is able to achieve about 90% accuracy. Although this is good, it can be imporved by trying different types of data rescaling techniques like rescaling to -1 to 1 scale or standardizing. We can also imporve the results by tuning the learning rate, the droupout rate, early stopping or trying different activiation functions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-projects",
   "language": "python",
   "name": "deep-learning-projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
